{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T18:56:31.728226Z",
     "start_time": "2025-12-11T18:56:31.725673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(df.columns)"
   ],
   "id": "560c97b26f617fae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'snapshot_ts', 'rev_id', 'timestamp', 'user', 'is_bot',\n",
      "       'article_id', 'title', 'root', 'stratum', 'content', 'p_t',\n",
      "       'lexical_spike_delta', 'perplexity', 'burstiness', 'upos_props',\n",
      "       'mean_dep_depth', 'clause_ratio', 'voice_ratio', 'fre', 'fog',\n",
      "       'chars_per_sent', 'sents_per_para', 'nTTR', 'word_density',\n",
      "       'avg_line_len', 'citation_delta', 'p_t_zscore',\n",
      "       'lexical_spike_delta_zscore', 'perplexity_zscore', 'burstiness_zscore',\n",
      "       'mean_dep_depth_zscore', 'clause_ratio_zscore', 'voice_ratio_zscore',\n",
      "       'fre_zscore', 'fog_zscore', 'chars_per_sent_zscore',\n",
      "       'sents_per_para_zscore', 'avg_line_len_zscore', 'nTTR_zscore',\n",
      "       'word_density_zscore', 'citation_delta_zscore', 'ai_vote_count',\n",
      "       'ai_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-14T18:25:14.625703Z",
     "start_time": "2025-12-14T18:25:08.212960Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "print(\"Loading data...\")\n",
    "\n",
    "csv_path = \"normalized_everything100percat_with_ai_votes.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Loaded Data from {csv_path}: {len(df)} rows\")\n",
    "\n",
    "    # --- FIX: Handle Column Renaming Safely ---\n",
    "    if 'plain_text' in df.columns:\n",
    "        print(\"Found 'plain_text' column.\")\n",
    "        # Check if 'content' already exists and drop it to prevent duplicates\n",
    "        if 'content' in df.columns:\n",
    "            print(\"Existing 'content' column detected. Dropping it to prefer 'plain_text'...\")\n",
    "            df.drop(columns=['content'], inplace=True)\n",
    "\n",
    "        df.rename(columns={'plain_text': 'content'}, inplace=True)\n",
    "        print(\"Renamed 'plain_text' to 'content'.\")\n",
    "    elif 'content' in df.columns:\n",
    "        print(\"Found 'content' column.\")\n",
    "    else:\n",
    "        print(\"WARNING: No text column found in CSV.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find {csv_path}.\")\n",
    "    raise\n",
    "\n",
    "# Ensure timestamp is datetime\n",
    "if 'snapshot_ts' in df.columns:\n",
    "    df['snapshot_ts'] = pd.to_datetime(df['snapshot_ts'])\n",
    "\n",
    "# --- CRITICAL FIX: Handle Index Duplicates ---\n",
    "# Check if index has duplicates\n",
    "if not df.index.is_unique:\n",
    "    print(\"WARNING: Duplicate index found. Resetting index...\")\n",
    "df = df.reset_index(drop=True)\n",
    "print(f\"Index unique: {df.index.is_unique}\")\n",
    "\n",
    "# --- 2. THE HUNT: Find Your Examples ---\n",
    "\n",
    "INTERVENTION_DATE = '2022-11-01'\n",
    "is_post_gpt = df['snapshot_ts'] > INTERVENTION_DATE\n",
    "\n",
    "# === SEARCH 1: The \"Passive Voice\" Anomaly ===\n",
    "# Context: You found a sharp drop in voice_ratio for Music/Video Games in Section 6.3.\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SEARCH 1: Passive Voice Anomalies (Music/Video Games)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "target_topics = ['Music', 'Video games']\n",
    "mask_topic = df['root'].isin(target_topics)\n",
    "\n",
    "# Ensure we are using the correct column and it is 1D\n",
    "if 'content' in df.columns:\n",
    "    # Defensive check: if duplicates still exist, take the first one\n",
    "    if isinstance(df['content'], pd.DataFrame):\n",
    "        print(\"Warning: Duplicate 'content' columns found. Selecting the first one.\")\n",
    "        content_series = df['content'].iloc[:, 0]\n",
    "    else:\n",
    "        content_series = df['content']\n",
    "    mask_not_nan = content_series.notna()\n",
    "else:\n",
    "    mask_not_nan = pd.Series([False] * len(df), index=df.index)\n",
    "\n",
    "# Combine masks\n",
    "subset_mask = is_post_gpt & mask_topic & mask_not_nan\n",
    "\n",
    "if len(subset_mask) != len(df):\n",
    "    print(\"Error: Mask length mismatch!\")\n",
    "else:\n",
    "    candidates = df.loc[subset_mask].copy()\n",
    "    # Looking for LOW voice_ratio (passive voice)\n",
    "    candidates = candidates.sort_values(by='voice_ratio', ascending=True).head(5)\n",
    "\n",
    "    for i, row in candidates.iterrows():\n",
    "        print(f\"\\n--- Candidate {i+1} [Topic: {row.get('root', 'N/A')}] ---\")\n",
    "        print(f\"Date: {row.get('snapshot_ts', 'N/A')} | Voice Ratio: {row.get('voice_ratio', 0):.4f}\")\n",
    "        content = str(row.get('content', 'NO CONTENT FOUND'))\n",
    "        print(f\"Snippet:\\n{content[:600]}...\\n\")\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded Data from normalized_everything100percat_with_ai_votes.csv: 15832 rows\n",
      "Found 'plain_text' column.\n",
      "Existing 'content' column detected. Dropping it to prefer 'plain_text'...\n",
      "Renamed 'plain_text' to 'content'.\n",
      "Index unique: True\n",
      "\n",
      "============================================================\n",
      "SEARCH 1: Passive Voice Anomalies (Music/Video Games)\n",
      "============================================================\n",
      "\n",
      "--- Candidate 7640 [Topic: Music] ---\n",
      "Date: 2023-09-30 00:00:00+00:00 | Voice Ratio: 0.9716\n",
      "Snippet:\n",
      "thumb|[[dominican rite|dominican missal, c. 1240, giving a portion of the accentus (historical museum of lausanne).]] accentus (or accentus ecclesiasticus ecclesiastical accent is a style of church music that emphasizes spoken word. it is often contrasted with concentus, an alternative style that emphasizes harmony. the terms accentus and concentus were probably introduced by andreas ornithoparchus in his musicae activae micrologus, published in leipzig in 1517. \"concentus might be chief ruler over all things that are sung...and accentus over all things that are read,\" according to ornithoparc...\n",
      "\n",
      "\n",
      "--- Candidate 7639 [Topic: Music] ---\n",
      "Date: 2023-08-31 00:00:00+00:00 | Voice Ratio: 0.9725\n",
      "Snippet:\n",
      "thumb|[[dominican rite|dominican missal, c. 1240, giving a portion of the accentus (historical museum of lausanne).]] accentus (or accentus ecclesiasticus ecclesiastical accent is a style of church music that emphasizes spoken word. it is often contrasted with concentus, an alternative style that emphasizes harmony. the terms accentus and concentus were probably introduced by andreas ornithoparchus in his musicae activae micrologus, leipzig, 1517. \"concentus might be chief ruler over all things that are sung...and accentus over all things that are read,\" according to ornithoparchus. the style ...\n",
      "\n",
      "\n",
      "--- Candidate 7727 [Topic: Music] ---\n",
      "Date: 2022-11-30 00:00:00+00:00 | Voice Ratio: 0.9735\n",
      "Snippet:\n",
      "underwater art refers to artworks that are designed for or performed in an underwater environment. underwater art often contributes to or is inspired by state of the art scientific discoveries about subaquatic properties, such as underwater vision or underwater acoustics. underwater music == underwater music is a form of music composition that is tailored to the specific behavior of sound underwater. underwater music can be performed or recorded underwater, for example in a swimming pool. the audience listens to underwater music either under or above the surface of the water, depending on how ...\n",
      "\n",
      "\n",
      "--- Candidate 7728 [Topic: Music] ---\n",
      "Date: 2022-12-31 00:00:00+00:00 | Voice Ratio: 0.9735\n",
      "Snippet:\n",
      "underwater art refers to artworks that are designed for or performed in an underwater environment. underwater art often contributes to or is inspired by state of the art scientific discoveries about subaquatic properties, such as underwater vision or underwater acoustics. underwater music == underwater music is a form of music composition that is tailored to the specific behavior of sound underwater. underwater music can be performed or recorded underwater, for example in a swimming pool. the audience listens to underwater music either under or above the surface of the water, depending on how ...\n",
      "\n",
      "\n",
      "--- Candidate 7729 [Topic: Music] ---\n",
      "Date: 2023-01-31 00:00:00+00:00 | Voice Ratio: 0.9735\n",
      "Snippet:\n",
      "underwater art refers to artworks that are designed for or performed in an underwater environment. underwater art often contributes to or is inspired by state of the art scientific discoveries about subaquatic properties, such as underwater vision or underwater acoustics. underwater music == underwater music is a form of music composition that is tailored to the specific behavior of sound underwater. underwater music can be performed or recorded underwater, for example in a swimming pool. the audience listens to underwater music either under or above the surface of the water, depending on how ...\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:41:07.234517Z",
     "start_time": "2025-12-09T17:41:06.672983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataframe as you did before\n",
    "# df = ...\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REFINED SEARCH 2: Vocabulary Dilution (Prose only)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Filter out \"Lists\" to find actual repetitive AI prose\n",
    "mask_comp = df['root'] == 'Computing'\n",
    "# Filter out rows where content starts with \"List of\" or \"This is a list\"\n",
    "mask_no_lists = ~df['content'].str.lower().str.startswith(('list of', 'this is a list'), na=False)\n",
    "\n",
    "candidates_vocab = df[is_post_gpt & mask_comp & mask_not_nan & mask_no_lists].copy()\n",
    "candidates_vocab = candidates_vocab.sort_values(by='nTTR', ascending=True).head(5)\n",
    "\n",
    "for i, row in candidates_vocab.iterrows():\n",
    "    print(f\"\\n--- Candidate {i+1} [Computing - PROSE] ---\")\n",
    "    print(f\"Date: {row.get('snapshot_ts', 'N/A')} | nTTR: {row.get('nTTR', 0):.4f}\")\n",
    "    print(f\"Snippet:\\n{str(row.get('content', ''))[:500]}...\\n\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REFINED SEARCH 3: The 'Edit War' (Dip & Revert)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 2. Calculate the 'Dip' and the 'Recovery' to find the Revert\n",
    "music_df = df[df['root'] == 'Music'].sort_values(['article_id', 'snapshot_ts'])\n",
    "\n",
    "music_df['prev_voice'] = music_df.groupby('article_id')['voice_ratio'].shift(1)\n",
    "music_df['next_voice'] = music_df.groupby('article_id')['voice_ratio'].shift(-1)\n",
    "\n",
    "# 'Drop' = Current - Previous (Did it drop?)\n",
    "# 'Recovery' = Next - Current (Did it jump back up?)\n",
    "music_df['drop'] = music_df['voice_ratio'] - music_df['prev_voice']\n",
    "music_df['recovery'] = music_df['next_voice'] - music_df['voice_ratio']\n",
    "\n",
    "# Look for a significant Drop followed by a significant Recovery\n",
    "# Lowered threshold to 0.05 based on your previous output\n",
    "edit_wars = music_df[\n",
    "    (music_df['drop'] < -0.05) &\n",
    "    (music_df['recovery'] > 0.05)\n",
    "].sort_values('drop', ascending=True)\n",
    "\n",
    "if not edit_wars.empty:\n",
    "    top_case = edit_wars.iloc[0]\n",
    "    print(f\"\\nFOUND EDIT WAR in Article ID: {top_case['article_id']}\")\n",
    "    print(f\"Date of Anomaly: {top_case['snapshot_ts']}\")\n",
    "    print(f\"The Drop (Change from prev): {top_case['drop']:.4f}\")\n",
    "    print(f\"The Revert (Change to next): {top_case['recovery']:.4f}\")\n",
    "\n",
    "    print(f\"\\n--- THE 'BOT' REVISION (The Dip) ---\")\n",
    "    print(f\"Voice Ratio: {top_case['voice_ratio']:.4f}\")\n",
    "    print(f\"Text:\\n{str(top_case.get('content', ''))[:600]}...\\n\")\n",
    "else:\n",
    "    print(\"No strict edit wars found. The anomaly might be in the 'Video games' category instead?\")"
   ],
   "id": "2491b087ecabfadd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "REFINED SEARCH 2: Vocabulary Dilution (Prose only)\n",
      "============================================================\n",
      "\n",
      "--- Candidate 1228 [Computing - PROSE] ---\n",
      "Date: 2023-01-31 00:00:00+00:00 | nTTR: 4.2905\n",
      "Snippet:\n",
      "thumb|[[ultraviolet photography, a visual technology that has applications in astronomy]] visual technology is the engineering discipline dealing with visual representation. ==types== visual technology includes photography, printing, augmented reality, virtual reality and video. ==see also== *audiovisual *audiovisual education *information and communications technology *medical imaging *multimedia *technology *visual arts *visual culture *visual perception *visual sociology ==references== ===wor...\n",
      "\n",
      "\n",
      "--- Candidate 1118 [Computing - PROSE] ---\n",
      "Date: 2023-01-31 00:00:00+00:00 | nTTR: 4.3466\n",
      "Snippet:\n",
      "an information system contingency plan (iscp is a pre-established plan for restoration of the services of a given information system after a disruption. the us national institute of standards and technology computer security resource center (csrc has published a special publication (sp named sp 800-34 guiding organizations as to how an iscp should be developed. ==references==...\n",
      "\n",
      "\n",
      "--- Candidate 1126 [Computing - PROSE] ---\n",
      "Date: 2023-02-28 00:00:00+00:00 | nTTR: 4.5108\n",
      "Snippet:\n",
      "an information system contingency plan (iscp is a pre-established plan for restoration of the services of a given information system after a disruption. the us national institute of standards and technology computer security resource center (csrc has published a special publication (sp named sp 800-34 guiding organizations as to how an iscp should be developed. ==references category:it risk management...\n",
      "\n",
      "\n",
      "--- Candidate 1128 [Computing - PROSE] ---\n",
      "Date: 2023-04-30 00:00:00+00:00 | nTTR: 4.6173\n",
      "Snippet:\n",
      "an information system contingency plan (iscp is a pre-established plan for restoration of the services of a given information system after a disruption. the us national institute of standards and technology computer security resource center (csrc has published a special publication (sp named sp 800-34 guiding organizations as to how an iscp should be developed. ==references== category:information systems category:it risk management...\n",
      "\n",
      "\n",
      "--- Candidate 1129 [Computing - PROSE] ---\n",
      "Date: 2023-08-31 00:00:00+00:00 | nTTR: 4.6173\n",
      "Snippet:\n",
      "an information system contingency plan (iscp is a pre-established plan for restoration of the services of a given information system after a disruption. the us national institute of standards and technology computer security resource center (csrc has published a special publication (sp named sp 800-34 guiding organizations as to how an iscp should be developed. ==references== category:information systems category:it risk management...\n",
      "\n",
      "\n",
      "============================================================\n",
      "REFINED SEARCH 3: The 'Edit War' (Dip & Revert)\n",
      "============================================================\n",
      "No strict edit wars found. The anomaly might be in the 'Video games' category instead?\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:40:01.159279Z",
     "start_time": "2025-12-09T17:40:01.142256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataframe (Assuming it's already loaded in your environment as 'df')\n",
    "# If not, uncomment the lines below:\n",
    "# df = pd.read_csv(\"normalized_everything100percat_with_ai_votes.csv\")\n",
    "# if 'content' in df.columns: df.drop(columns=['content'], inplace=True)\n",
    "# df.rename(columns={'plain_text': 'content'}, inplace=True)\n",
    "# df['snapshot_ts'] = pd.to_datetime(df['snapshot_ts'])\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL SEARCH: The 'Edit War' in Video Games\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Focus on Video Games\n",
    "vg_df = df[df['root'] == 'Video games'].copy()\n",
    "vg_df = vg_df.sort_values(['article_id', 'snapshot_ts'])\n",
    "\n",
    "# 2. Calculate Shifts (Previous and Next month's voice ratio)\n",
    "vg_df['prev_voice'] = vg_df.groupby('article_id')['voice_ratio'].shift(1)\n",
    "vg_df['next_voice'] = vg_df.groupby('article_id')['voice_ratio'].shift(-1)\n",
    "\n",
    "# 3. Define the Anatomy of an Edit War\n",
    "# The Dip: Current voice is much lower than Previous\n",
    "vg_df['drop_size'] = vg_df['prev_voice'] - vg_df['voice_ratio']\n",
    "# The Revert: Next voice is much higher than Current\n",
    "vg_df['recovery_size'] = vg_df['next_voice'] - vg_df['voice_ratio']\n",
    "\n",
    "# 4. Filter for the \"V-Shape\" Pattern\n",
    "# We look for a massive drop (> 0.3) followed by a massive recovery (> 0.3)\n",
    "# This corresponds to the visual \"spike down\" in your plots.\n",
    "candidates = vg_df[\n",
    "    (vg_df['drop_size'] > 0.3) &\n",
    "    (vg_df['recovery_size'] > 0.3)\n",
    "]\n",
    "\n",
    "if not candidates.empty:\n",
    "    top_case = candidates.sort_values('drop_size', ascending=False).iloc[0]\n",
    "\n",
    "    print(f\"FOUND SMOKING GUN in Article ID: {top_case['article_id']}\")\n",
    "    print(f\"Title: {top_case.get('title', 'Unknown')}\")\n",
    "    print(f\"Date of Bot Attack: {top_case['snapshot_ts']}\")\n",
    "    print(f\"Voice Ratio (The Dip): {top_case['voice_ratio']:.4f}\")\n",
    "    print(f\"Previous Ratio: {top_case['prev_voice']:.4f} -> Dropped by {top_case['drop_size']:.4f}\")\n",
    "    print(f\"Next Ratio: {top_case['next_voice']:.4f} -> Recovered by {top_case['recovery_size']:.4f}\")\n",
    "\n",
    "    print(f\"\\n--- THE ANOMALY TEXT (Passive Voice Bot) ---\")\n",
    "    print(f\"{str(top_case.get('content', ''))[:1000]}...\")\n",
    "\n",
    "else:\n",
    "    print(\"No massive V-shaped edit wars found. Trying looser thresholds (0.1)...\")\n",
    "    candidates_loose = vg_df[(vg_df['drop_size'] > 0.1) & (vg_df['recovery_size'] > 0.1)]\n",
    "    if not candidates_loose.empty:\n",
    "        top_case = candidates_loose.sort_values('drop_size', ascending=False).iloc[0]\n",
    "        print(f\"Found smaller edit war in Article: {top_case['title']}\")\n",
    "        print(f\"Date: {top_case['snapshot_ts']}\")\n",
    "        print(f\"Content snippet: {str(top_case.get('content', ''))[:300]}...\")\n",
    "    else:\n",
    "        print(\"Still nothing. Check if the 'Video games' category name is correct in your CSV.\")"
   ],
   "id": "8c970a3b2042ae94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL SEARCH: The 'Edit War' in Video Games\n",
      "============================================================\n",
      "FOUND SMOKING GUN in Article ID: 19120\n",
      "Title: Revolution 60\n",
      "Date of Bot Attack: 2023-03-31 00:00:00+00:00\n",
      "Voice Ratio (The Dip): 0.0000\n",
      "Previous Ratio: 0.9901 -> Dropped by 0.9901\n",
      "Next Ratio: 0.9879 -> Recovered by 0.9879\n",
      "\n",
      "--- THE ANOMALY TEXT (Passive Voice Bot) ---\n",
      "nan...\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:13:28.987264Z",
     "start_time": "2025-12-09T17:13:28.980107Z"
    }
   },
   "cell_type": "code",
   "source": "print(df)",
   "id": "a081d578e4286bb9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0               snapshot_ts      rev_id  \\\n",
      "0               0 2023-06-30 00:00:00+00:00  1160763005   \n",
      "1               1 2023-07-31 00:00:00+00:00  1166013433   \n",
      "2               2 2023-08-31 00:00:00+00:00  1171485250   \n",
      "3               3 2023-09-30 00:00:00+00:00  1177319025   \n",
      "4               4 2023-10-31 00:00:00+00:00  1181899435   \n",
      "...           ...                       ...         ...   \n",
      "15827       15827 2023-12-31 00:00:00+00:00  1190712502   \n",
      "15828       15828 2024-01-31 00:00:00+00:00  1197552616   \n",
      "15829       15829 2023-08-31 00:00:00+00:00  1172064757   \n",
      "15830       15830 2023-10-31 00:00:00+00:00  1181427482   \n",
      "15831       15831 2023-11-30 00:00:00+00:00  1184252783   \n",
      "\n",
      "                       timestamp                                   user  \\\n",
      "0      2023-06-18 16:30:41+00:00  2601:483:C301:7360:BC05:287F:176:F15F   \n",
      "1      2023-07-18 21:17:52+00:00                             TompaDompa   \n",
      "2      2023-08-21 11:13:21+00:00                           79.41.96.200   \n",
      "3      2023-09-27 04:45:15+00:00                         187.254.98.237   \n",
      "4      2023-10-25 22:06:39+00:00                              Idulatria   \n",
      "...                          ...                                    ...   \n",
      "15827  2023-12-19 11:44:12+00:00                                 Mika1h   \n",
      "15828  2024-01-21 00:52:22+00:00                                Venky64   \n",
      "15829  2023-08-24 18:34:01+00:00                                CurlyWi   \n",
      "15830  2023-10-23 00:04:28+00:00                              Radja Dwm   \n",
      "15831  2023-11-09 07:24:13+00:00                            Underbar dk   \n",
      "\n",
      "       is_bot                                            content  article_id  \\\n",
      "0       False  {{Use dmy dates|date=July 2021}}\\n{{Short desc...       20951   \n",
      "1       False  {{Use dmy dates|date=July 2021}}\\n{{Short desc...       20951   \n",
      "2       False  {{Use dmy dates|date=July 2021}}\\n{{Short desc...       20951   \n",
      "3       False  {{Use dmy dates|date=July 2021}}\\n{{Short desc...       20951   \n",
      "4       False  {{Use dmy dates|date=July 2021}}\\n{{Short desc...       20951   \n",
      "...       ...                                                ...         ...   \n",
      "15827   False  {{more citations needed|date=April 2023}}\\n{{I...        8654   \n",
      "15828   False  {{more citations needed|date=April 2023}}\\n{{I...        8654   \n",
      "15829   False  {{Infobox video game\\n| collapsible = \\n| ital...       10527   \n",
      "15830   False  {{Infobox video game\\n| collapsible = \\n| ital...       10527   \n",
      "15831   False  {{Infobox video game\\n| collapsible = \\n| ital...       10527   \n",
      "\n",
      "                   title         root  ... fre_zscore fog_zscore  \\\n",
      "0        List of empires      History  ...  -4.327842   6.045270   \n",
      "1        List of empires      History  ...  -4.281436   5.973193   \n",
      "2        List of empires      History  ...  -4.326513   6.034735   \n",
      "3        List of empires      History  ...  -4.309285   6.021318   \n",
      "4        List of empires      History  ...  -4.323714   6.039556   \n",
      "...                  ...          ...  ...        ...        ...   \n",
      "15827  Pac-Man All-Stars  Video games  ...  -0.338468  -1.103966   \n",
      "15828  Pac-Man All-Stars  Video games  ...  -0.353607  -1.112477   \n",
      "15829      Idol Showdown  Video games  ...   0.133137  -1.828332   \n",
      "15830      Idol Showdown  Video games  ...  -0.036570  -1.441546   \n",
      "15831      Idol Showdown  Video games  ...  -0.036570  -1.441546   \n",
      "\n",
      "       chars_per_sent_zscore  sents_per_para_zscore  avg_line_len_zscore  \\\n",
      "0                   0.543670              -0.965933            -0.837440   \n",
      "1                   0.464213              -0.958110            -0.840029   \n",
      "2                   0.475988              -0.958110            -0.837633   \n",
      "3                   0.543078              -0.965933            -0.837556   \n",
      "4                   0.476368              -0.958110            -0.837556   \n",
      "...                      ...                    ...                  ...   \n",
      "15827              -1.121026              -0.807131            -0.983865   \n",
      "15828              -1.147850              -0.807131            -0.986427   \n",
      "15829              -0.920569              -0.558323            -0.754252   \n",
      "15830              -0.863354              -0.500906            -0.694054   \n",
      "15831              -0.863354              -0.500906            -0.694054   \n",
      "\n",
      "       nTTR_zscore word_density_zscore  citation_delta_zscore  ai_vote_count  \\\n",
      "0        -0.782697            0.110041              -1.315955              3   \n",
      "1        -0.698040            0.122510              -1.313476              3   \n",
      "2        -0.698040            0.116385              -1.315791              3   \n",
      "3        -0.698040            0.116189              -1.246176              3   \n",
      "4        -0.698040            0.116189              -1.246176              3   \n",
      "...            ...                 ...                    ...            ...   \n",
      "15827     1.306311            3.336936               0.040132              2   \n",
      "15828     0.998153            3.260247               0.033969              1   \n",
      "15829    -0.533352            0.632742              -0.545341              0   \n",
      "15830    -0.279023            0.431931              -0.763382              0   \n",
      "15831    -0.279023            0.431931              -0.763382              0   \n",
      "\n",
      "       ai_flag  \n",
      "0        False  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False  \n",
      "...        ...  \n",
      "15827    False  \n",
      "15828    False  \n",
      "15829    False  \n",
      "15830    False  \n",
      "15831    False  \n",
      "\n",
      "[15832 rows x 45 columns]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T18:42:18.251789Z",
     "start_time": "2025-12-09T18:42:12.269943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "csv_path = \"normalized_everything100percat_with_ai_votes.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Robust Column Cleaning\n",
    "    if 'plain_text' in df.columns:\n",
    "        if 'content' in df.columns: df.drop(columns=['content'], inplace=True)\n",
    "        df.rename(columns={'plain_text': 'content'}, inplace=True)\n",
    "\n",
    "    # Fix Types\n",
    "    if 'snapshot_ts' in df.columns: df['snapshot_ts'] = pd.to_datetime(df['snapshot_ts'])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Filter for Post-ChatGPT\n",
    "    is_post_gpt = df['snapshot_ts'] > '2022-11-01'\n",
    "    # Ensure text exists\n",
    "    has_text = df['content'].notna() & (df['content'].str.len() > 100)\n",
    "\n",
    "    print(\"Data loaded and filtered.\")\n",
    "\n",
    "    # --- SEARCH 1: The \"Unsourced Generator\" (Citation Drops) ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SEARCH 1: The 'Unsourced Generator' (Citation Drops)\")\n",
    "    print(\"=\"*60)\n",
    "    # Logic: High AI Votes BUT Negative Citation Delta (Removing refs while writing)\n",
    "    # We want valid text, Post-GPT, High Votes, Negative Citations\n",
    "\n",
    "    mask_citation = (df['citation_delta_zscore'] < -1.0) # Significantly negative\n",
    "    mask_high_risk = (df['ai_vote_count'] >= 2) # At least suspicious\n",
    "\n",
    "    candidates_cit = df[is_post_gpt & has_text & mask_citation & mask_high_risk].copy()\n",
    "\n",
    "    # Sort by how MANY citations were dropped (lowest zscore)\n",
    "    candidates_cit = candidates_cit.sort_values('citation_delta_zscore', ascending=True).head(3)\n",
    "\n",
    "    for i, row in candidates_cit.iterrows():\n",
    "        print(f\"\\n--- Candidate {i+1} [Topic: {row.get('root')}] ---\")\n",
    "        print(f\"Date: {row.get('snapshot_ts')} | AI Votes: {row.get('ai_vote_count')}\")\n",
    "        print(f\"Citation Delta Z-Score: {row.get('citation_delta_zscore'):.4f} (Removing Refs!)\")\n",
    "        print(f\"Snippet:\\n{str(row.get('content'))[:400]}...\\n\")\n",
    "\n",
    "    # --- SEARCH 2: The \"Narrative Bot\" (Political History) ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SEARCH 2: The 'Narrative Bot' (Political History)\")\n",
    "    print(\"=\"*60)\n",
    "    # Logic: Political History, High Confidence (Votes >= 3), Not a List\n",
    "\n",
    "    mask_pol = df['root'] == 'Political history'\n",
    "    mask_confident = df['ai_vote_count'] >= 3\n",
    "    # Filter out \"List of\" titles to get pure narrative\n",
    "    mask_narrative = ~df['title'].str.startswith('List of', na=False)\n",
    "\n",
    "    candidates_pol = df[is_post_gpt & has_text & mask_pol & mask_confident & mask_narrative].copy()\n",
    "\n",
    "    # Sort by date (latest first to see recent advanced bots) or Voice Ratio (passive)\n",
    "    candidates_pol = candidates_pol.sort_values('snapshot_ts', ascending=False).head(3)\n",
    "\n",
    "    for i, row in candidates_pol.iterrows():\n",
    "        print(f\"\\n--- Candidate {i+1} [Title: {row.get('title')}] ---\")\n",
    "        print(f\"Date: {row.get('snapshot_ts')} | AI Votes: {row.get('ai_vote_count')}\")\n",
    "        print(f\"Voice Ratio: {row.get('voice_ratio'):.4f} | Perplexity: {row.get('perplexity'):.4f}\")\n",
    "        print(f\"Snippet:\\n{str(row.get('content'))[:400]}...\\n\")\n",
    "\n",
    "    # --- SEARCH 3: The \"Subtle Polisher\" (Chemistry) ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SEARCH 3: The 'Subtle Polisher' (Chemistry)\")\n",
    "    print(\"=\"*60)\n",
    "    # Logic: Chemistry, Votes == 2 (High Sensitivity only), Post-GPT\n",
    "    # This finds the \"hidden\" AI that your High-Reliability model missed\n",
    "\n",
    "    mask_chem = df['root'] == 'Chemistry'\n",
    "    mask_subtle = df['ai_vote_count'] == 2 # Exactly 2 votes (The \"Maybe\" zone)\n",
    "\n",
    "    candidates_chem = df[is_post_gpt & has_text & mask_chem & mask_subtle].copy()\n",
    "    candidates_chem = candidates_chem.head(3)\n",
    "\n",
    "    for i, row in candidates_chem.iterrows():\n",
    "        print(f\"\\n--- Candidate {i+1} [Title: {row.get('title')}] ---\")\n",
    "        print(f\"Date: {row.get('snapshot_ts')} | AI Votes: {row.get('ai_vote_count')}\")\n",
    "        print(f\"Snippet:\\n{str(row.get('content'))[:400]}...\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ],
   "id": "d168420e36ae1432",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded and filtered.\n",
      "\n",
      "============================================================\n",
      "SEARCH 1: The 'Unsourced Generator' (Citation Drops)\n",
      "============================================================\n",
      "\n",
      "--- Candidate 15198 [Topic: Video games] ---\n",
      "Date: 2023-10-31 00:00:00+00:00 | AI Votes: 5\n",
      "Citation Delta Z-Score: -2.3390 (Removing Refs!)\n",
      "Snippet:\n",
      "{{multiple issues| }} {{infobox video game |image=csi crime city.jpg |caption= |developer=area/code |publisher=ubisoft |designer= |engine= |released 2010 |genre=adventure |modes=single player |platforms=facebook }} csi crime city was the eleventh video game adaptation of the csi crime scene investigation television series, developed for facebook by american studio area/code and published by ubisof...\n",
      "\n",
      "\n",
      "--- Candidate 6826 [Topic: Medicine] ---\n",
      "Date: 2023-10-31 00:00:00+00:00 | AI Votes: 2\n",
      "Citation Delta Z-Score: -1.9141 (Removing Refs!)\n",
      "Snippet:\n",
      "{{multiple issues| }} pancrinol was a medicine made from liver, spleen, kidney, and adrenal extracts from slaughter animals. it was manufactured by the laboratories of dr. françois debat in paris. this drug was presented, in drinkable ampoules, as a tonic against anemia, tuberculosis, and all organic deficiencies. it was used as a doping agent in cycling. ==bibliography revue art et médecine, no. ...\n",
      "\n",
      "\n",
      "--- Candidate 6605 [Topic: Medicine] ---\n",
      "Date: 2023-08-31 00:00:00+00:00 | AI Votes: 4\n",
      "Citation Delta Z-Score: -1.9141 (Removing Refs!)\n",
      "Snippet:\n",
      "this is a list of notable journals related to medical and health informatics. thumb|impact factors of scholarly journals publishing digital health (ehealth, mhealth work *bmc medical informatics and decision making *bmj health care informatics *computers in biology and medicine *health informatics journal *international journal of medical informatics *journal of the american medical informatics as...\n",
      "\n",
      "\n",
      "============================================================\n",
      "SEARCH 2: The 'Narrative Bot' (Political History)\n",
      "============================================================\n",
      "\n",
      "--- Candidate 9213 [Title: ICJ case on Israel's occupation of the Palestinian territories] ---\n",
      "Date: 2024-01-31 00:00:00+00:00 | AI Votes: 4\n",
      "Voice Ratio: 0.9950 | Perplexity: 367.9561\n",
      "Snippet:\n",
      "{{infobox court case |name legal consequences arising from the policies and practices of israel in the occupied palestinian territory, including east jerusalem |court international court of justice |image |imagesize |imagelink |imagealt |caption |full name legal consequences arising from the policies and practices of israel in the occupied palestinian territory, including east jerusalem (request f...\n",
      "\n",
      "\n",
      "--- Candidate 9494 [Title: Acts of Union 1707] ---\n",
      "Date: 2024-01-31 00:00:00+00:00 | AI Votes: 5\n",
      "Voice Ratio: 0.9941 | Perplexity: 739.1805\n",
      "Snippet:\n",
      "{{infobox uk legislation short_title union with scotland act 1706 type act parliament parliament of england long_title an act for a union of the two kingdoms of england and scotland. year 1706 citation 6 ann. c. 11(ruffhead 5 ann. c. 8 introduced_commons introduced_lords territorial_extent kingdom of england royal_assent 6 march 1707 commencement 1 may 1707 expiry_date repeal_date amends replaces ...\n",
      "\n",
      "\n",
      "--- Candidate 9015 [Title: Khivan campaign of 1839?1840] ---\n",
      "Date: 2024-01-31 00:00:00+00:00 | AI Votes: 3\n",
      "Voice Ratio: 0.9755 | Perplexity: 700.9726\n",
      "Snippet:\n",
      "{{infobox military conflict conflict russo-khivan war of 1839?1840 partof russian conquest of turkestan image caption date 10 october 1839 ? june 1840 place khiva (present-day western uzbekistan, southwestern kazakhstan and much of turkmenistan result khivan-kazakhs victory russian invasion of khiva repelled combatant1 border|22px khiva junior juz combatant2 border|22px russia commander1 border|22...\n",
      "\n",
      "\n",
      "============================================================\n",
      "SEARCH 3: The 'Subtle Polisher' (Chemistry)\n",
      "============================================================\n",
      "\n",
      "--- Candidate 905 [Title: Deoxycorticosterone] ---\n",
      "Date: 2023-11-30 00:00:00+00:00 | AI Votes: 2\n",
      "Snippet:\n",
      "deoxycorticosterone (doc), or desoxycorticosterone, may refer to 11-deoxycorticosterone (21-hydroxyprogesterone 21-deoxycorticosterone (11?-hydroxyprogesterone) ==see also deoxycortisol deoxycortisone 11-hydroxyprogesterone category:pregnanes...\n",
      "\n",
      "\n",
      "--- Candidate 922 [Title: Butyl ester] ---\n",
      "Date: 2022-12-31 00:00:00+00:00 | AI Votes: 2\n",
      "Snippet:\n",
      "butyl ester may refer to butyl nitrite the family of organic chemical compounds containing an ester group and a butyl group including butyl acetate butyl acrylate butyl butyrate butyl cyanoacrylate butyl methacrylate dibutyl phthalate ==external links== category:butyl compounds...\n",
      "\n",
      "\n",
      "--- Candidate 923 [Title: Butyl ester] ---\n",
      "Date: 2023-12-31 00:00:00+00:00 | AI Votes: 2\n",
      "Snippet:\n",
      "butyl ester may refer to butyl nitrite the family of organic chemical compounds containing an ester group and a butyl group including butyl acetate butyl acrylate butyl butyrate butyl cyanoacrylate butyl methacrylate dibutyl phthalate ==external links...\n",
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T19:07:30.202063Z",
     "start_time": "2025-12-09T19:07:10.392407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "csv_path = \"normalized_everything100percat_with_ai_votes.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'plain_text' in df.columns:\n",
    "        if 'content' in df.columns: df.drop(columns=['content'], inplace=True)\n",
    "        df.rename(columns={'plain_text': 'content'}, inplace=True)\n",
    "\n",
    "    if 'snapshot_ts' in df.columns: df['snapshot_ts'] = pd.to_datetime(df['snapshot_ts'])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    is_post_gpt = df['snapshot_ts'] > '2022-11-01'\n",
    "    has_text = df['content'].notna() & (df['content'].str.len() > 100)\n",
    "\n",
    "    print(\"Data loaded and filtered.\")\n",
    "\n",
    "    # --- HELPER: Smart Context Extractor ---\n",
    "    def get_context_snippet(text, keywords, window=250):\n",
    "        \"\"\"Finds the keyword in the text and returns a window around it.\"\"\"\n",
    "        text_str = str(text)\n",
    "        # Create a regex pattern to find any of the keywords\n",
    "        pattern = '|'.join(map(re.escape, keywords)) if isinstance(keywords, list) else keywords\n",
    "\n",
    "        match = re.search(pattern, text_str, re.IGNORECASE)\n",
    "        if match:\n",
    "            # Found it! Calculate start/end to center the match\n",
    "            start = max(0, match.start() - window)\n",
    "            end = min(len(text_str), match.end() + window)\n",
    "            prefix = \"...\" if start > 0 else \"\"\n",
    "            suffix = \"...\" if end < len(text_str) else \"\"\n",
    "            return f\"{prefix}{text_str[start:end]}{suffix}\"\n",
    "        else:\n",
    "            # Fallback: Return the beginning if no specific keyword match (for style searches)\n",
    "            return text_str[:500] + \"...\"\n",
    "\n",
    "    # --- SEARCH 4: The \"Model Leak\" (Context-Aware) ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SEARCH 4: The 'Model Leak' (Showing the ACTUAL Artifact)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    leak_keywords = [\n",
    "        \"as an ai language model\", \"i cannot\", \"i don't have personal\",\n",
    "        \"knowledge cutoff\", \"regenerate response\", \"september 2021\"\n",
    "    ]\n",
    "\n",
    "    # Use regex for filtering\n",
    "    pattern = '|'.join(leak_keywords)\n",
    "    mask_leak = df['content'].str.contains(pattern, case=False, na=False)\n",
    "    candidates_leak = df[is_post_gpt & has_text & mask_leak].copy()\n",
    "\n",
    "    if not candidates_leak.empty:\n",
    "        for i, row in candidates_leak.head(5).iterrows():\n",
    "            print(f\"\\n--- Candidate {i+1} [Title: {row.get('title')}] ---\")\n",
    "            print(f\"Date: {row.get('snapshot_ts')} | AI Votes: {row.get('ai_vote_count')}\")\n",
    "\n",
    "            # USE THE NEW FUNCTION HERE\n",
    "            snippet = get_context_snippet(row.get('content'), leak_keywords)\n",
    "            print(f\"Snippet:\\n{snippet}\\n\")\n",
    "    else:\n",
    "        print(\"No obvious leaks found.\")\n",
    "\n",
    "\n",
    "    # --- SEARCH 5: The \"History Sanitizer\" (Passive Voice) ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SEARCH 5: The 'History Sanitizer' (Politics + Passive Voice)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    mask_politics = df['root'].isin(['Political history', 'Politics', 'Military history'])\n",
    "    candidates_sanitizer = df[is_post_gpt & has_text & mask_politics & (df['ai_vote_count'] >= 3)].copy()\n",
    "    candidates_sanitizer = candidates_sanitizer.sort_values('voice_ratio', ascending=True).head(3)\n",
    "\n",
    "    for i, row in candidates_sanitizer.iterrows():\n",
    "        print(f\"\\n--- Candidate {i+1} [Title: {row.get('title')}] ---\")\n",
    "        print(f\"Date: {row.get('snapshot_ts')} | Voice Ratio: {row.get('voice_ratio'):.4f}\")\n",
    "        # For style, we want the intro, but let's grab MORE text (1000 chars) to see the pattern\n",
    "        print(f\"Snippet:\\n{str(row.get('content'))[:1000]}...\\n\")\n",
    "\n",
    "\n",
    "    # --- SEARCH 6: The \"Cultural Flattener\" (Robotic Pop Culture) ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SEARCH 6: The 'Cultural Flattener' (Pop Culture + Low Burstiness)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    mask_pop = df['root'].isin(['Popular culture', 'Film', 'Video games'])\n",
    "    candidates_flat = df[is_post_gpt & has_text & mask_pop & (df['ai_vote_count'] >= 3)].copy()\n",
    "    candidates_flat = candidates_flat.sort_values('burstiness', ascending=True).head(3)\n",
    "\n",
    "    for i, row in candidates_flat.iterrows():\n",
    "        print(f\"\\n--- Candidate {i+1} [Title: {row.get('title')}] ---\")\n",
    "        print(f\"Date: {row.get('snapshot_ts')} | Burstiness: {row.get('burstiness'):.4f}\")\n",
    "        # Grab more text to show the repetitive structure\n",
    "        print(f\"Snippet:\\n{str(row.get('content'))[:1000]}...\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ],
   "id": "f8b84f333a95d256",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded and filtered.\n",
      "\n",
      "============================================================\n",
      "SEARCH 4: The 'Model Leak' (Showing the ACTUAL Artifact)\n",
      "============================================================\n",
      "\n",
      "--- Candidate 116 [Title: Extrajudicial killing] ---\n",
      "Date: 2022-11-30 00:00:00+00:00 | AI Votes: 0\n",
      "Snippet:\n",
      "...go. egypt ==== extrajudicial killings and death squads are common in egypt. egypt recorded and reported more than a dozen unlawful extrajudicial killings of apparent ?terrorists? in the country by the nsa officers and the interior ministry police in september 2021. a 101-page report detailed the ?armed militants? being killed in shootouts despite not posing any threat to the security forces or nations of the country while being killed, which in many cases were already in custody. statements by the family and ...\n",
      "\n",
      "\n",
      "--- Candidate 117 [Title: Extrajudicial killing] ---\n",
      "Date: 2022-12-31 00:00:00+00:00 | AI Votes: 0\n",
      "Snippet:\n",
      "...go. egypt ==== extrajudicial killings and death squads are common in egypt. egypt recorded and reported more than a dozen unlawful extrajudicial killings of apparent ?terrorists? in the country by the nsa officers and the interior ministry police in september 2021. a 101-page report detailed the ?armed militants? being killed in shootouts despite not posing any threat to the security forces or nations of the country while being killed, which in many cases were already in custody. statements by the family and ...\n",
      "\n",
      "\n",
      "--- Candidate 118 [Title: Extrajudicial killing] ---\n",
      "Date: 2023-02-28 00:00:00+00:00 | AI Votes: 0\n",
      "Snippet:\n",
      "...go. egypt ==== extrajudicial killings and death squads are common in egypt. egypt recorded and reported more than a dozen unlawful extrajudicial killings of apparent ?terrorists? in the country by the nsa officers and the interior ministry police in september 2021. a 101-page report detailed the ?armed militants? being killed in shootouts despite not posing any threat to the security forces or nations of the country while being killed, which in many cases were already in custody. statements by the family and ...\n",
      "\n",
      "\n",
      "--- Candidate 119 [Title: Extrajudicial killing] ---\n",
      "Date: 2023-03-31 00:00:00+00:00 | AI Votes: 0\n",
      "Snippet:\n",
      "...go. egypt ==== extrajudicial killings and death squads are common in egypt. egypt recorded and reported more than a dozen unlawful extrajudicial killings of apparent ?terrorists? in the country by the nsa officers and the interior ministry police in september 2021. a 101-page report detailed the ?armed militants? being killed in shootouts despite not posing any threat to the security forces or nations of the country while being killed, which in many cases were already in custody. statements by the family and ...\n",
      "\n",
      "\n",
      "--- Candidate 120 [Title: Extrajudicial killing] ---\n",
      "Date: 2023-04-30 00:00:00+00:00 | AI Votes: 0\n",
      "Snippet:\n",
      "...go. egypt ==== extrajudicial killings and death squads are common in egypt. egypt recorded and reported more than a dozen unlawful extrajudicial killings of apparent ?terrorists? in the country by the nsa officers and the interior ministry police in september 2021. a 101-page report detailed the ?armed militants? being killed in shootouts despite not posing any threat to the security forces or nations of the country while being killed, which in many cases were already in custody. statements by the family and ...\n",
      "\n",
      "\n",
      "============================================================\n",
      "SEARCH 5: The 'History Sanitizer' (Politics + Passive Voice)\n",
      "============================================================\n",
      "\n",
      "--- Candidate 9012 [Title: Khivan campaign of 1839?1840] ---\n",
      "Date: 2023-08-31 00:00:00+00:00 | Voice Ratio: 0.9755\n",
      "Snippet:\n",
      "{{infobox military conflict |conflict russo-khivan war of 1839?1840 |partof russian conquest of turkestan |image = |caption = |date 10 october 1839 ? june 1840 |place khiva (present-day western uzbekistan, southwestern kazakhstan and much of turkmenistan) |result khivan victory russian invasion of khiva repelled |combatant1 border|22px khiva |combatant2 border|22px russia |commander1 allah quli bahadur |commander2 border|22px nicholas i <br border|22px vasily perovsky |strength1 unknown |strength2 6651 troops |casualties1 unknown |casualties2 2,500 killed or died of diseases }} the russo-khivan war of 1839?1840 was a failed russian attempt to conquer the khanate of khiva. vasily perovsky set out from orenburg with 5,000 men, met an unusually cold winter, lost most of his camels, and was forced to turn back after going halfway. russians attacked khiva four times. around 1602, some free cossacks made three raids on khiva. in 1717, alexander bekovich-cherkassky attacked khiva and was soun...\n",
      "\n",
      "\n",
      "--- Candidate 9013 [Title: Khivan campaign of 1839?1840] ---\n",
      "Date: 2023-10-31 00:00:00+00:00 | Voice Ratio: 0.9755\n",
      "Snippet:\n",
      "{{infobox military conflict |conflict russo-khivan war of 1839?1840 |partof russian conquest of turkestan |image = |caption = |date 10 october 1839 ? june 1840 |place khiva (present-day western uzbekistan, southwestern kazakhstan and much of turkmenistan) |result khivan victory russian invasion of khiva repelled |combatant1 border|22px khiva |combatant2 border|22px russia |commander1 border|22px allah quli bahadur |commander2 border|22px nicholas i <br border|22px vasily perovsky |strength1 unknown |strength2 6651 troops |casualties1 unknown |casualties2 2,500 killed or died of diseases }} the russo-khivan war of 1839?1840 was a failed russian attempt to conquer the khanate of khiva. vasily perovsky set out from orenburg with 5,000 men, met an unusually cold winter, lost most of his camels, and was forced to turn back after going halfway. russians attacked khiva four times. around 1602, some free cossacks made three raids on khiva. in 1717, alexander bekovich-cherkassky attacked khiva ...\n",
      "\n",
      "\n",
      "--- Candidate 9010 [Title: Khivan campaign of 1839?1840] ---\n",
      "Date: 2023-02-28 00:00:00+00:00 | Voice Ratio: 0.9755\n",
      "Snippet:\n",
      "{{infobox military conflict |conflict russo-khivan war of 1839?1840 |partof russian conquest of turkestan |image = |caption = |date 10 october 1839 ? june 1840 |place khiva (present-day western uzbekistan, southwestern kazakhstan and much of turkmenistan) |result khivan victory russian invasion of khiva repelled |combatant1 border|22px khiva |combatant2 border|22px russia |commander1 allah quli bahadur |commander2 border|22px nicholas i <br border|22px vasily perovsky |strength1 unknown |strength2 5,000 troops |casualties1 unknown |casualties2 1,054 killed or died of diseases }} the russo-khivan war of 1839?1840 was a failed russian attempt to conquer the khanate of khiva. vasily perovsky set out from orenburg with 5,000 men, met an unusually cold winter, lost most of his camels, and was forced to turn back after going halfway. russians attacked khiva four times. around 1602, some free cossacks made three raids on khiva. in 1717, alexander bekovich-cherkassky attacked khiva and was sou...\n",
      "\n",
      "\n",
      "============================================================\n",
      "SEARCH 6: The 'Cultural Flattener' (Pop Culture + Low Burstiness)\n",
      "============================================================\n",
      "\n",
      "--- Candidate 15198 [Title: CSI: Crime City] ---\n",
      "Date: 2023-10-31 00:00:00+00:00 | Burstiness: 0.0292\n",
      "Snippet:\n",
      "{{multiple issues| }} {{infobox video game |image=csi crime city.jpg |caption= |developer=area/code |publisher=ubisoft |designer= |engine= |released 2010 |genre=adventure |modes=single player |platforms=facebook }} csi crime city was the eleventh video game adaptation of the csi crime scene investigation television series, developed for facebook by american studio area/code and published by ubisoft. it was the third csi game released during 2010, along with csi fatal conspiracy and csi unsolved. when case set 12 was released, it brought the game up to 61 cases. the game has been shut down as of march 13, 2015. ==case set 1== ===case 1 sweet revenge=== victim(s tommy suspects curtis candy crime scenes casino penthouse, strip club bathroom tommy is up on the roof of the casino penthouse when candy and curtis arrive. tommy talks to candy of some plan they had arranged. tommy then asks candy who the person standing near the door is (curtis), curtis then says that they had other ideas. at t...\n",
      "\n",
      "\n",
      "--- Candidate 15608 [Title: Tribal Trouble] ---\n",
      "Date: 2023-04-30 00:00:00+00:00 | Burstiness: 0.0997\n",
      "Snippet:\n",
      "{{infobox video game title tribal trouble image developer oddlabs publisher garagegames designer engine released march 31, 2005 genre real-time strategy modes multiplayer platforms microsoft windows, mac os x, linux }} tribal trouble is a real-time strategy video game for pc. the game pits natives of tropical islands against invading vikings. the game was originally developed by independent studio oddlabs. the game was well received by the press and has won several awards. ==gameplay development and release == the game was originally developed by independent studio oddlabs and released on march 31, 2005. it was released for microsoft windows, mac os x, and linux. in september 2014 the game's source code was released to the public on github and is now open source under the gplv2. development continues in a community fork. reception == inside mac games reviewed the game. the game has won several awards, including four top 5 positions in indie game review site gametunnel's 2005 awards in ...\n",
      "\n",
      "\n",
      "--- Candidate 11581 [Title: PC Master Race] ---\n",
      "Date: 2022-11-30 00:00:00+00:00 | Burstiness: 0.1633\n",
      "Snippet:\n",
      "thumb|350px|an example of a dedicated [[gaming computer|gaming-pc rig]] the pc master race (abbreviated pcmr), sometimes referred to by its original phrasing as the glorious pc gaming master race, is an internet subculture, internet community, and a tongue-in-cheek term of superiority for pc gaming used among gamers to compare pc gaming to console gaming.<ref name=\"newstatesman\"/><ref name=\"twsextremetech\"/> in current parlance, the term is commonly used by pc enthusiasts both to describe themselves as a group, as well as their belief in the superiority of the pc platform in comparison to consoles, often citing features like more advanced graphics, higher framerates, free online play, wider variety of games, backwards compatibility, modifications, upgradability, customization, lower cost-over-time, open standards, multitasking, and performance.<ref name=\"ignsuperior\"/><ref name=\"lifehacker\" popular imagery, discussion, and media referencing the term also commonly describes console user...\n",
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T19:36:12.653051Z",
     "start_time": "2025-12-09T19:35:54.770403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "csv_path = \"normalized_everything100percat_with_ai_votes.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'plain_text' in df.columns:\n",
    "        if 'content' in df.columns: df.drop(columns=['content'], inplace=True)\n",
    "        df.rename(columns={'plain_text': 'content'}, inplace=True)\n",
    "\n",
    "    if 'snapshot_ts' in df.columns: df['snapshot_ts'] = pd.to_datetime(df['snapshot_ts'])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    is_post_gpt = df['snapshot_ts'] > '2022-11-01'\n",
    "    has_text = df['content'].notna() & (df['content'].str.len() > 100)\n",
    "\n",
    "    # --- SEARCH 4 (REFINED): The \"True\" Model Leak ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SEARCH 4: The 'True' Model Leak (Refusals Only)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # REMOVED \"september 2021\" and \"knowledge cutoff\" to avoid false positives\n",
    "    leak_keywords = [\n",
    "        \"as an ai language model\",\n",
    "        \"i cannot\",\n",
    "        \"i don't have personal\",\n",
    "        \"regenerate response\",\n",
    "        \"i am an ai\"\n",
    "    ]\n",
    "\n",
    "    pattern = '|'.join(leak_keywords)\n",
    "    mask_leak = df['content'].str.contains(pattern, case=False, na=False)\n",
    "    candidates_leak = df[is_post_gpt & has_text & mask_leak].copy()\n",
    "\n",
    "    if not candidates_leak.empty:\n",
    "        print(f\"FOUND {len(candidates_leak)} TRUE LEAKS!\")\n",
    "        for i, row in candidates_leak.head(3).iterrows():\n",
    "            print(f\"\\n--- Candidate {i+1} [Title: {row.get('title')}] ---\")\n",
    "\n",
    "            # Smart Snippet: Find the keyword and show context\n",
    "            text_str = str(row.get('content'))\n",
    "            for key in leak_keywords:\n",
    "                match = re.search(re.escape(key), text_str, re.IGNORECASE)\n",
    "                if match:\n",
    "                    start = max(0, match.start() - 100)\n",
    "                    end = min(len(text_str), match.end() + 100)\n",
    "                    print(f\"MATCHED KEYWORD: '{key}'\")\n",
    "                    print(f\"Snippet: ...{text_str[start:end]}...\\n\")\n",
    "                    break # Show only the first match per article\n",
    "    else:\n",
    "        print(\"No text-based leaks found (Cleaned by editors?).\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ],
   "id": "358f139eab8b1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "============================================================\n",
      "SEARCH 4: The 'True' Model Leak (Refusals Only)\n",
      "============================================================\n",
      "FOUND 66 TRUE LEAKS!\n",
      "\n",
      "--- Candidate 2096 [Title: Socialist democracy] ---\n",
      "MATCHED KEYWORD: 'i cannot'\n",
      "Snippet: ...the abolition of private property and to the possibilities inherent in planned economy. but, they - i cannot say exactly - but i will say two or three times less than they could be under a regime of soviet de...\n",
      "\n",
      "\n",
      "--- Candidate 2097 [Title: Socialist democracy] ---\n",
      "MATCHED KEYWORD: 'i cannot'\n",
      "Snippet: ...the abolition of private property and to the possibilities inherent in planned economy. but, they - i cannot say exactly - but i will say two or three times less than they could be under a regime of soviet de...\n",
      "\n",
      "\n",
      "--- Candidate 2098 [Title: Socialist democracy] ---\n",
      "MATCHED KEYWORD: 'i cannot'\n",
      "Snippet: ...the abolition of private property and to the possibilities inherent in planned economy. but, they - i cannot say exactly - but i will say two or three times less than they could be under a regime of soviet de...\n",
      "\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "41553b5500bc702f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T20:08:09.271719Z",
     "start_time": "2025-12-11T20:07:56.254491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_CSV_PATH = \"normalized_everything100percat_with_ai_votes.csv\"\n",
    "# Update this path if needed (e.g., \"python_code/combined_chatgpt_words.csv\")\n",
    "WORDS_CSV_PATH = \"combined_chatgpt_words.csv\"\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "try:\n",
    "    # 1. Load Data & Words\n",
    "    df = pd.read_csv(DATA_CSV_PATH)\n",
    "    try:\n",
    "        words_df = pd.read_csv(WORDS_CSV_PATH)\n",
    "        raw_vocab = set(words_df.iloc[:, 0].dropna().astype(str).str.lower())\n",
    "    except Exception as e:\n",
    "        # Fallback if file not found\n",
    "        print(f\"Warning: Could not load word list ({e}). Using fallback.\")\n",
    "        raw_vocab = {\"delve\", \"tapestry\", \"landscape\", \"testament\", \"underscore\", \"intricate\", \"paramount\", \"leverage\", \"robust\", \"seamless\"}\n",
    "\n",
    "    # 2. Clean the Data\n",
    "    if 'plain_text' in df.columns:\n",
    "        if 'content' in df.columns: df.drop(columns=['content'], inplace=True)\n",
    "        df.rename(columns={'plain_text': 'content'}, inplace=True)\n",
    "    if 'snapshot_ts' in df.columns: df['snapshot_ts'] = pd.to_datetime(df['snapshot_ts'])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # 3. Refine the Vocabulary (Remove common false positives)\n",
    "    banned_words = {\n",
    "        'data', 'source', 'information', 'system', 'list', 'image', 'file', 'link',\n",
    "        'external', 'history', 'series', 'version', 'development', 'release',\n",
    "        'game', 'film', 'music', 'album', 'song', 'voice', 'social', 'party',\n",
    "        'ongoing', 'include', 'current', 'world', 'science', 'note', 'action',\n",
    "        'university', 'school', 'research', 'area', 'field'\n",
    "    }\n",
    "    spicy_vocab = [w for w in raw_vocab if w not in banned_words and len(w) > 4]\n",
    "\n",
    "    print(f\"Refined Vocabulary: {len(spicy_vocab)} words\")\n",
    "\n",
    "    # 4. Target Specific Categories\n",
    "    target_roots = ['Computing', 'Technology', 'Engineering', 'Business']\n",
    "\n",
    "    subset = df[\n",
    "        (df['snapshot_ts'] > '2022-11-01') &\n",
    "        (df['root'].isin(target_roots)) &\n",
    "        (df['content'].notna()) &\n",
    "        (df['content'].str.len() > 500)\n",
    "    ].copy()\n",
    "\n",
    "    # --- THE SMART SCORER ---\n",
    "    def get_prose_score(row):\n",
    "        text = str(row['content']).lower()\n",
    "        title_words = set(str(row['title']).lower().split())\n",
    "\n",
    "        # Contextual Filtering: Ignore words if they are in the Title\n",
    "        local_vocab = [w for w in spicy_vocab if w not in title_words]\n",
    "\n",
    "        # Count hits (checking common boundaries)\n",
    "        # Using regex here would be slower but more accurate; simple string match is fast\n",
    "        hits = [w for w in local_vocab if f\" {w} \" in text or f\" {w}.\" in text or f\" {w},\" in text]\n",
    "        unique_hits = len(set(hits))\n",
    "\n",
    "        # Penalize lists (high newline ratio)\n",
    "        if text.count('\\n') > text.count(' ') / 5:\n",
    "            return 0, []\n",
    "\n",
    "        return unique_hits, list(set(hits))\n",
    "\n",
    "    # Apply scoring\n",
    "    subset[['spicy_score', 'spicy_words']] = subset.apply(\n",
    "        lambda row: pd.Series(get_prose_score(row)), axis=1\n",
    "    )\n",
    "\n",
    "    # --- FIX 1: DEDUPLICATION ---\n",
    "    # Sort by score descending first so we keep the \"spiciest\" revision\n",
    "    subset = subset.sort_values('spicy_score', ascending=False)\n",
    "    # Drop duplicates by article_id, keeping the first (highest score)\n",
    "    unique_candidates = subset.drop_duplicates(subset='article_id', keep='first')\n",
    "\n",
    "    # Get top 5 unique articles\n",
    "    top_prose = unique_candidates.head(5)\n",
    "\n",
    "    # --- FIX 2: IMPROVED SNIPPET EXTRACTOR ---\n",
    "    def extract_densest_snippet(text, target_words, window_size=600):\n",
    "        \"\"\"\n",
    "        Finds the window of text containing the highest density of target words.\n",
    "        \"\"\"\n",
    "        text_lower = text.lower()\n",
    "        word_indices = []\n",
    "\n",
    "        # Find all start indices of target words using Regex for proper boundaries\n",
    "        for w in target_words:\n",
    "            for match in re.finditer(r'\\b' + re.escape(w) + r'\\b', text_lower):\n",
    "                word_indices.append(match.start())\n",
    "\n",
    "        if not word_indices:\n",
    "            return text[:window_size] + \"...\" # Fallback\n",
    "\n",
    "        word_indices.sort()\n",
    "\n",
    "        # Sliding window to find max density\n",
    "        max_words_in_window = 0\n",
    "        best_center = word_indices[0]\n",
    "\n",
    "        # Check around each word occurrence\n",
    "        for center_idx in word_indices:\n",
    "            start_window = max(0, center_idx - window_size // 2)\n",
    "            end_window = min(len(text), center_idx + window_size // 2)\n",
    "\n",
    "            # Count how many keyword hits fall inside this window\n",
    "            count = sum(1 for wi in word_indices if start_window <= wi < end_window)\n",
    "\n",
    "            if count > max_words_in_window:\n",
    "                max_words_in_window = count\n",
    "                best_center = center_idx\n",
    "\n",
    "        # Extract the best window\n",
    "        start = max(0, best_center - window_size // 2)\n",
    "        end = min(len(text), best_center + window_size // 2)\n",
    "\n",
    "        # Clean up newlines for display\n",
    "        snippet = text[start:end].replace('\\n', ' ')\n",
    "        return f\"...{snippet}...\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SEARCH RESULT: The 'Purple Prose' Generators (Unique & Focused)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    for i, row in top_prose.iterrows():\n",
    "        print(f\"\\n--- Candidate {i} [Topic: {row['root']} | Title: {row['title']}] ---\")\n",
    "        print(f\"Unique AI Words: {row['spicy_score']} | Votes: {row['ai_vote_count']}\")\n",
    "        print(f\"Words Found: {row['spicy_words'][:10]}...\")\n",
    "\n",
    "        snippet = extract_densest_snippet(str(row['content']), row['spicy_words'])\n",
    "        print(f\"Snippet:\\n{snippet}\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ],
   "id": "1ea3ce91b2458f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Refined Vocabulary: 284 words\n",
      "\n",
      "============================================================\n",
      "SEARCH RESULT: The 'Purple Prose' Generators (Unique & Focused)\n",
      "============================================================\n",
      "\n",
      "--- Candidate 13367 [Topic: Technology | Title: Glossary of engineering: M?Z] ---\n",
      "Unique AI Words: 86 | Votes: 2\n",
      "Words Found: ['drive', 'stability', 'ultimately', 'integrate', 'address', 'interact', 'significant', 'efficient', 'critical', 'arguably']...\n",
      "Snippet:\n",
      "...ral tendency\")</ref><ref name=dodge1>dodge, y. (2003 the oxford dictionary of statistical terms, oup for international statistical institute. (entry for \"central tendency\")</ref> the central tendency of a distribution is typically contrasted with its dispersion or variability dispersion and central tendency are the often characterized properties of distributions. analysis may judge whether data has a strong or a weak central tendency based on its dispersion.}} </ref an ideal mechanism transmits power without adding to or subtracting from it. this means the ideal mechanism does not include a po...\n",
      "\n",
      "\n",
      "--- Candidate 11184 [Topic: Technology | Title: Filter bubble] ---\n",
      "Unique AI Words: 80 | Votes: 0\n",
      "Words Found: ['targeted', 'growth', 'prevent', 'address', 'reverberate', 'significant', 'query', 'critical', 'achieve', 'determine']...\n",
      "Snippet:\n",
      "...on that appeals to their preconceptions. older americans usually remain stagnant in their political views as traditional media outlets continue to be a primary source of news, while online media is the leading source for the younger demographic. although algorithms and filter bubbles weaken content diversity, this study reveals that political polarization trends are primarily driven by pre-existing views and failure to recognize outside sources. a 2020 study from germany utilized the big five psychology model to test the effects of individual personality, demographics, and ideologies on user n...\n",
      "\n",
      "\n",
      "--- Candidate 1492 [Topic: Computing | Title: Gender digital divide] ---\n",
      "Unique AI Words: 77 | Votes: 0\n",
      "Words Found: ['targeted', 'growth', 'ultimately', 'prevent', 'ensure', 'critical', 'deliver', 'accelerate', 'potential', 'whether']...\n",
      "Snippet:\n",
      "...onger families, stronger communities, stronger economies and better technology.<ref name=\":0\" digital skills are recognized to be essential life skills required for full participation in society. the main benefits for acquiring digital skills are they:<ref name=\":0\" facilitate entry into the labour market assist women's safety both online and offline enhance women's community and political engagement bring economic benefits to women and society empower women to help steer the future of technology and gender equality accelerate progress towards international goals.<ref name=\":0\" /> digitalizati...\n",
      "\n",
      "\n",
      "--- Candidate 13625 [Topic: Technology | Title: Disruptive innovation] ---\n",
      "Unique AI Words: 73 | Votes: 0\n",
      "Words Found: ['drive', 'growth', 'challenging', 'ultimately', 'adopt', 'produce', 'prevent', 'particularly', 'beyond', 'daily']...\n",
      "Snippet:\n",
      "...ce. a proactive approach to disruptive innovation == a proactive approach to addressing the challenge posited by disruptive innovations has been debated by scholars. petzold criticized the lack of acknowledgment of underlying process of the change to study the disruptive innovation over time from a process view and complexify the concept to support the understanding of its unfolding and advance its manageability. keeping in view the multidimensional nature of disruptive innovation a measurement framework has been developed by guo to enable a systemic assessment of disruptive potential of innov...\n",
      "\n",
      "\n",
      "--- Candidate 13996 [Topic: Technology | Title: Environmental impact assessment] ---\n",
      "Unique AI Words: 68 | Votes: 0\n",
      "Words Found: ['contribute', 'overall', 'strategic', 'analysis', 'particularly', 'proponent', 'trend', 'address', 'consider', 'important']...\n",
      "Snippet:\n",
      "... may be subject to judicial review. the purpose of the assessment is to ensure that decision-makers consider the environmental impacts when deciding whether or not to proceed with a project. the international association for impact assessment (iaia defines an environmental impact assessment as \"the process of identifying, predicting, evaluating and mitigating the biophysical, social, and other relevant effects of development proposals prior to major decisions being taken and commitments made\". eias are unique in that they do not require adherence to a predetermined environmental outcome, but r...\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:38:31.886771Z",
     "start_time": "2025-12-14T18:38:31.870219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print row for “Acts of Union 1707” (Political History, Jan 2024).\n",
    "\n",
    "\n",
    "# print(df[df['title'] == 'Acts of Union 1707'])\n",
    "\n",
    "# print row for Khivan campaign of 1839–1840\"\n",
    "# print(df[df['title'] == 'Khivan campaign of 1839–1840'])\n",
    "\n",
    "# print rows whose tittle contains Khivan campaign\n",
    "print(df[df['title'].str.contains('Khivan campaign')])"
   ],
   "id": "7914d429f2c094d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0               snapshot_ts      rev_id  \\\n",
      "9005        9005 2022-01-31 00:00:00+00:00  1064889049   \n",
      "9006        9006 2022-02-28 00:00:00+00:00  1072179533   \n",
      "9007        9007 2022-09-30 00:00:00+00:00  1107789906   \n",
      "9008        9008 2022-10-31 00:00:00+00:00  1117528644   \n",
      "9009        9009 2023-02-28 00:00:00+00:00  1137662854   \n",
      "9010        9010 2023-04-30 00:00:00+00:00  1149493915   \n",
      "9011        9011 2023-08-31 00:00:00+00:00  1172967014   \n",
      "9012        9012 2023-10-31 00:00:00+00:00  1179966538   \n",
      "9013        9013 2023-12-31 00:00:00+00:00  1187624065   \n",
      "9014        9014 2024-01-31 00:00:00+00:00  1197452333   \n",
      "\n",
      "                      timestamp               user  is_bot  article_id  \\\n",
      "9005  2022-01-10 18:26:18+00:00      MrBismark1871   False       23097   \n",
      "9006  2022-02-16 09:53:18+00:00   Benjamin Trovato   False       23097   \n",
      "9007  2022-08-31 22:25:44+00:00        Jay D. Easy   False       23097   \n",
      "9008  2022-10-22 06:14:49+00:00    124.246.112.183   False       23097   \n",
      "9009  2023-02-05 20:51:08+00:00          Lowellian   False       23097   \n",
      "9010  2023-04-12 15:57:35+00:00  Nederlandse Leeuw   False       23097   \n",
      "9011  2023-08-30 12:59:28+00:00      Batyikhan 4-5   False       23097   \n",
      "9012  2023-10-13 16:34:34+00:00            Hjoka78   False       23097   \n",
      "9013  2023-11-30 11:49:38+00:00       194.0.245.49   False       23097   \n",
      "9014  2024-01-20 15:35:04+00:00            Hjoka78   False       23097   \n",
      "\n",
      "                             title               root   stratum  ...  \\\n",
      "9005  Khivan campaign of 1839?1840  Political history  Politics  ...   \n",
      "9006  Khivan campaign of 1839?1840  Political history  Politics  ...   \n",
      "9007  Khivan campaign of 1839?1840  Political history  Politics  ...   \n",
      "9008  Khivan campaign of 1839?1840  Political history  Politics  ...   \n",
      "9009  Khivan campaign of 1839?1840  Political history  Politics  ...   \n",
      "9010  Khivan campaign of 1839?1840  Political history  Politics  ...   \n",
      "9011  Khivan campaign of 1839?1840  Political history  Politics  ...   \n",
      "9012  Khivan campaign of 1839?1840  Political history  Politics  ...   \n",
      "9013  Khivan campaign of 1839?1840  Political history  Politics  ...   \n",
      "9014  Khivan campaign of 1839?1840  Political history  Politics  ...   \n",
      "\n",
      "     fre_zscore  fog_zscore  chars_per_sent_zscore  sents_per_para_zscore  \\\n",
      "9005   2.786612   -2.735957              -1.387224              -0.430061   \n",
      "9006   2.744954   -2.681763              -1.352391              -0.430061   \n",
      "9007   2.724752   -2.646386              -1.352391              -0.430061   \n",
      "9008   2.725806   -2.643912              -1.363768              -0.430061   \n",
      "9009   2.724568   -2.644482              -1.364329              -0.430061   \n",
      "9010   2.719183   -2.635086              -1.362644              -0.430061   \n",
      "9011   2.722084   -2.637346              -1.366998              -0.430061   \n",
      "9012   2.719391   -2.636782              -1.365313              -0.430061   \n",
      "9013   2.708641   -2.626269              -1.362925              -0.430061   \n",
      "9014   2.708641   -2.626269              -1.362784              -0.430061   \n",
      "\n",
      "      avg_line_len_zscore nTTR_zscore  word_density_zscore  \\\n",
      "9005            -0.659972    0.545973             0.290109   \n",
      "9006            -0.653108    0.545973             0.259551   \n",
      "9007            -0.653108    0.545973             0.259551   \n",
      "9008            -0.655350    0.545973             0.269365   \n",
      "9009            -0.655460    0.545973             0.269853   \n",
      "9010            -0.655128    0.545973             0.268388   \n",
      "9011            -0.655986    0.599047             0.279333   \n",
      "9012            -0.655654    0.545973             0.270710   \n",
      "9013            -0.655184    0.705194             0.290028   \n",
      "9014            -0.655156    0.705194             0.289904   \n",
      "\n",
      "      citation_delta_zscore  ai_vote_count  ai_flag  \n",
      "9005              -1.240981              3    False  \n",
      "9006              -1.173671              3    False  \n",
      "9007              -1.172407              3    False  \n",
      "9008              -1.170184              3    False  \n",
      "9009              -1.169865              3    False  \n",
      "9010              -1.170502              3    False  \n",
      "9011              -1.168906              3    False  \n",
      "9012              -1.170502              3    False  \n",
      "9013              -1.176495              3    False  \n",
      "9014              -1.176495              3    False  \n",
      "\n",
      "[10 rows x 44 columns]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:42:33.519023Z",
     "start_time": "2025-12-14T18:42:27.004121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_CSV_PATH = \"normalized_everything100percat_with_ai_votes.csv\"\n",
    "\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    df = pd.read_csv(DATA_CSV_PATH)\n",
    "\n",
    "    # 1. Clean Dates & Fix Timezone\n",
    "    if 'snapshot_ts' in df.columns:\n",
    "        df['snapshot_ts'] = pd.to_datetime(df['snapshot_ts'])\n",
    "        # Standardize to UTC to avoid comparison errors\n",
    "        if df['snapshot_ts'].dt.tz is None:\n",
    "             df['snapshot_ts'] = df['snapshot_ts'].dt.tz_localize('UTC')\n",
    "        else:\n",
    "             df['snapshot_ts'] = df['snapshot_ts'].dt.tz_convert('UTC')\n",
    "\n",
    "    # 2. Define ChatGPT Release Date (UTC)\n",
    "    GPT_RELEASE_DATE = pd.Timestamp('2022-11-30').tz_localize('UTC')\n",
    "\n",
    "    # 3. Create \"Pre\" and \"Post\" Groups\n",
    "    pre_gpt = df[df['snapshot_ts'] < GPT_RELEASE_DATE]\n",
    "    post_gpt = df[df['snapshot_ts'] >= GPT_RELEASE_DATE]\n",
    "\n",
    "    # 4. Aggregate Scores\n",
    "    pre_stats = pre_gpt.groupby(['article_id', 'title', 'root'])['ai_vote_count'].mean().reset_index(name='pre_score')\n",
    "    post_stats = post_gpt.groupby(['article_id', 'title', 'root'])['ai_vote_count'].mean().reset_index(name='post_score')\n",
    "\n",
    "    # 5. Merge and Calculate Delta\n",
    "    comparison = pd.merge(pre_stats, post_stats, on=['article_id', 'title', 'root'], how='inner')\n",
    "    comparison['delta'] = comparison['post_score'] - comparison['pre_score']\n",
    "\n",
    "    # 6. Filter for TRUE Transformations\n",
    "    # pre_score < 1.5 (Was Human)\n",
    "    # post_score >= 3.0 (Became AI)\n",
    "    # delta >= 2.0 (Significant Jump)\n",
    "    transformations = comparison[\n",
    "        (comparison['pre_score'] < 1.5) &\n",
    "        (comparison['post_score'] >= 3.0) &\n",
    "        (comparison['delta'] >= 2.0)\n",
    "    ].sort_values('delta', ascending=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"FOUND {len(transformations)} ARTICLES WITH A SIGNIFICANT SHIFT\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    if not transformations.empty:\n",
    "        print(transformations[['title', 'root', 'pre_score', 'post_score', 'delta']].head(5))\n",
    "\n",
    "        # Extract the best example for your thesis\n",
    "        top_row = transformations.iloc[0]\n",
    "        t_id = top_row['article_id']\n",
    "        t_title = top_row['title']\n",
    "\n",
    "        print(f\"\\n--- Best Candidate: {t_title} ---\")\n",
    "\n",
    "        # Get the text before and after the shift\n",
    "        history = df[df['article_id'] == t_id].sort_values('snapshot_ts')\n",
    "\n",
    "        # Get one human revision (pre-Nov 2022)\n",
    "        human_rev = history[history['snapshot_ts'] < GPT_RELEASE_DATE].tail(1)\n",
    "        # Get one AI revision (post-Nov 2022 with high vote)\n",
    "        ai_rev = history[(history['snapshot_ts'] >= GPT_RELEASE_DATE) & (history['ai_vote_count'] >= 4)].head(1)\n",
    "\n",
    "        if not human_rev.empty and not ai_rev.empty:\n",
    "            print(\"\\nBEFORE (Human):\")\n",
    "            print(human_rev['content'].values[0][:300] + \"...\")\n",
    "            print(\"\\nAFTER (AI):\")\n",
    "            print(ai_rev['content'].values[0][:300] + \"...\")\n",
    "\n",
    "    else:\n",
    "        print(\"No articles found with strict criteria. Try pre_score < 2.0.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ],
   "id": "c06991f545aece28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "================================================================================\n",
      "FOUND 0 ARTICLES WITH A SIGNIFICANT SHIFT\n",
      "================================================================================\n",
      "No articles found with strict criteria. Try pre_score < 2.0.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:46:14.860658Z",
     "start_time": "2025-12-14T18:46:08.418455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_CSV_PATH = \"normalized_everything100percat_with_ai_votes.csv\"\n",
    "\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    df = pd.read_csv(DATA_CSV_PATH)\n",
    "\n",
    "    # 1. Clean Dates & Fix Timezone\n",
    "    if 'snapshot_ts' in df.columns:\n",
    "        df['snapshot_ts'] = pd.to_datetime(df['snapshot_ts'])\n",
    "        if df['snapshot_ts'].dt.tz is None:\n",
    "             df['snapshot_ts'] = df['snapshot_ts'].dt.tz_localize('UTC')\n",
    "        else:\n",
    "             df['snapshot_ts'] = df['snapshot_ts'].dt.tz_convert('UTC')\n",
    "\n",
    "    GPT_RELEASE_DATE = pd.Timestamp('2022-11-30').tz_localize('UTC')\n",
    "\n",
    "    # 2. Split Data\n",
    "    pre_gpt = df[df['snapshot_ts'] < GPT_RELEASE_DATE]\n",
    "    post_gpt = df[df['snapshot_ts'] >= GPT_RELEASE_DATE]\n",
    "\n",
    "    # 3. The \"Spike\" Strategy (Compare MAX scores, not Means)\n",
    "    # Find the highest AI score an article EVER received in each period\n",
    "    pre_max = pre_gpt.groupby(['article_id', 'title', 'root'])['ai_vote_count'].max().reset_index(name='pre_max')\n",
    "    post_max = post_gpt.groupby(['article_id', 'title', 'root'])['ai_vote_count'].max().reset_index(name='post_max')\n",
    "\n",
    "    # 4. Merge\n",
    "    comparison = pd.merge(pre_max, post_max, on=['article_id', 'title', 'root'], how='inner')\n",
    "\n",
    "    # 5. Filter: The \"Clean Hit\" Candidates\n",
    "    # - Before GPT: It NEVER looked like AI (Max < 2)\n",
    "    # - After GPT: It had at least one HIGH confidence AI flag (Max >= 4)\n",
    "    # - This eliminates the \"Structural False Positives\" like Acts of Union (which had high scores before)\n",
    "    candidates = comparison[\n",
    "        (comparison['pre_max'] <= 2) &\n",
    "        (comparison['post_max'] >= 4)\n",
    "    ].sort_values('post_max', ascending=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"FOUND {len(candidates)} ARTICLES WITH A SUDDEN AI SPIKE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    if not candidates.empty:\n",
    "        print(candidates.head(10))\n",
    "\n",
    "        # --- Extract the \"Smoking Gun\" Revision ---\n",
    "        top_row = candidates.iloc[0]\n",
    "        t_id = top_row['article_id']\n",
    "        t_title = top_row['title']\n",
    "\n",
    "        print(f\"\\n--- DEEP DIVE: {t_title} ---\")\n",
    "\n",
    "        # Get the specific revision that triggered the spike\n",
    "        spike_rev = post_gpt[\n",
    "            (post_gpt['article_id'] == t_id) &\n",
    "            (post_gpt['ai_vote_count'] == top_row['post_max'])\n",
    "        ].iloc[0]\n",
    "\n",
    "        print(f\"Spike Date: {spike_rev['snapshot_ts']}\")\n",
    "        print(f\"AI Vote Count: {spike_rev['ai_vote_count']}\")\n",
    "        print(f\"Snippet:\\n{str(spike_rev.get('content', ''))[:500]}...\")\n",
    "\n",
    "    else:\n",
    "        print(\"Still no results. This confirms that High AI Scores in this dataset are predominantly Structural (Pre-existing).\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ],
   "id": "e1306d229a2fa9f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "================================================================================\n",
      "FOUND 3 ARTICLES WITH A SUDDEN AI SPIKE\n",
      "================================================================================\n",
      "      article_id                                    title         root  \\\n",
      "934        19120                            Revolution 60  Video games   \n",
      "643        13515  Centre for Free Elections and Democracy    Elections   \n",
      "1064       21631                             1981 in film         Film   \n",
      "\n",
      "      pre_max  post_max  \n",
      "934         0         9  \n",
      "643         2         4  \n",
      "1064        2         4  \n",
      "\n",
      "--- DEEP DIVE: Revolution 60 ---\n",
      "Spike Date: 2023-03-31 00:00:00+00:00\n",
      "AI Vote Count: 9\n",
      "Snippet:\n",
      "nan...\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:47:59.184355Z",
     "start_time": "2025-12-14T18:47:59.168552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter for the specific legitimate candidates we found\n",
    "target_titles = [\"Centre for Free Elections and Democracy\", \"1981 in film\"]\n",
    "\n",
    "print(\"Fetching snippets for valid candidates...\\n\")\n",
    "\n",
    "for title in target_titles:\n",
    "    # Get revisions for this article\n",
    "    article_revs = df[df['title'] == title]\n",
    "\n",
    "    # Find the \"Spike\" revision (Score >= 4)\n",
    "    spike_rev = article_revs[article_revs['ai_vote_count'] >= 4].sort_values('snapshot_ts').iloc[0]\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(f\"TITLE: {title}\")\n",
    "    print(f\"Spike Date: {spike_rev['snapshot_ts']}\")\n",
    "    print(f\"Score: {spike_rev['ai_vote_count']}\")\n",
    "    print(\"-\" * 20)\n",
    "    # Print the first 500 characters of the content\n",
    "    content = str(spike_rev.get('content', 'No content found'))\n",
    "    print(f\"Snippet:\\n{content[:500]}...\")\n",
    "    print(\"=\"*60 + \"\\n\")"
   ],
   "id": "7b370379c57a04c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching snippets for valid candidates...\n",
      "\n",
      "============================================================\n",
      "TITLE: Centre for Free Elections and Democracy\n",
      "Spike Date: 2023-12-31 00:00:00+00:00\n",
      "Score: 4\n",
      "--------------------\n",
      "Snippet:\n",
      "{{short description|Non-governmental organization in Serbia}}\n",
      "{{Third-party|date=December 2023}}\n",
      "{{use dmy dates|date=January 2023}}\n",
      "{{Infobox organization\n",
      "| name                = CeSID\n",
      "| full_name           = Centre for Free Elections and Democracy\n",
      "| native_name         = ?????? ?? ???????? ?????? ? ???????????<br />Centar za slobodne izbore i demokratiju\n",
      "| native_name_lang    = sr\n",
      "| logo                = CeSID logo.png\n",
      "| formation           = 1997\n",
      "| founder             = [[Marko Blagojevi? (bo...\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TITLE: 1981 in film\n",
      "Spike Date: 2024-01-31 00:00:00+00:00\n",
      "Score: 4\n",
      "--------------------\n",
      "Snippet:\n",
      "{{short description|Overview of the events of 1981 in film}}\n",
      "{{Year nav topic5|1981|film|radio|television|music}}\n",
      "{{Yearsinfilm}}\n",
      "The following is an overview of events in '''1981 in film''', including the highest-grossing films, award ceremonies and festivals, a list of films released and notable deaths.\n",
      "\n",
      "==Highest-grossing films (U.S.)==\n",
      "{{See also|List of 1981 box office number-one films in the United States}}\n",
      "The top ten films released in 1981 by box office gross in North America are as foll...\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
