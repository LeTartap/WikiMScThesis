{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T20:29:45.354840Z",
     "start_time": "2026-02-05T20:29:44.560273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "# A GUIDE TO CODING INTERRUPTED TIME SERIES (ITS) ANALYSIS\n",
    "# Adapted for the Wikipedia Revisions DataFrame\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ],
   "id": "e552c72cf0615d9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T20:29:45.365861Z",
     "start_time": "2026-02-05T20:29:45.358673Z"
    }
   },
   "cell_type": "code",
   "source": "input_files = [\"normalized_everything100percat_with_ai_votes-ZST2.5-MV2.csv\",\"normalized_everything100percat_with_ai_votes-ZST2.5-MV3.csv\", \"normalized_everything100percat_with_ai_votes-ZST2-MV2.csv\"]",
   "id": "40b89efca466d8c3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T20:29:45.374266Z",
     "start_time": "2026-02-05T20:29:45.367791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "input_file = \"normalized_everything100percat_with_ai_votes.csv\""
   ],
   "id": "9039cc9853a02e54",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T20:31:54.766109Z",
     "start_time": "2026-02-05T20:31:52.712388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print all root categories in the dataset\n",
    "catdf = pd.read_csv(input_file, usecols=['stratum'])\n",
    "catdf['stratum'].unique()\n"
   ],
   "id": "cbc192d74136afa0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['History', 'Politics', 'Technology', 'Science & Medicine',\n",
       "       'Popular Culture'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-01T20:46:20.573193Z",
     "start_time": "2026-02-01T20:46:20.563203Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "def run_its_analysis(df_monthly, feature_to_analyze, intervention_date, show_plot=True, print_summary=True):\n",
    "    \"\"\"\n",
    "    Performs an Interrupted Time Series (ITS) analysis for a specified feature.\n",
    "\n",
    "    Args:\n",
    "        df_monthly (pd.DataFrame): DataFrame with monthly aggregated data.\n",
    "                                   Must include 'snapshot_ts', 'time', 'intervention',\n",
    "                                   and 'post_intervention_time' columns.\n",
    "        feature_to_analyze (str): The name of the dependent variable column to analyze.\n",
    "        intervention_date (pd.Timestamp): The date of the intervention.\n",
    "        show_plot (bool): If True, displays the ITS plot. Defaults to True.\n",
    "        print_summary (bool): If True, prints the model summary and diagnostics. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        statsmodels.regression.linear_model.RegressionResultsWrapper: The fitted model object.\n",
    "    \"\"\"\n",
    "    if feature_to_analyze not in df_monthly.columns:\n",
    "        print(f\"Error: Feature '{feature_to_analyze}' not found in the DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    if df_monthly[feature_to_analyze].isnull().all():\n",
    "        print(f\"Skipping '{feature_to_analyze}' because it contains only NaN values.\")\n",
    "        return None\n",
    "\n",
    "    # --- Step 4: Specify and Fit the ITS Model ---\n",
    "    model_formula = f'{feature_to_analyze} ~ time + intervention + post_intervention_time'\n",
    "    model = smf.ols(formula=model_formula, data=df_monthly).fit()\n",
    "\n",
    "    if print_summary:\n",
    "        # --- Step 5: Interpret the Model Results ---\n",
    "        print(f\"\\n--- ITS Model Results for '{feature_to_analyze}' ---\")\n",
    "        print(model.summary())\n",
    "\n",
    "        # --- Step 7: Diagnostic Check for Autocorrelation ---\n",
    "        durbin_watson_stat = sm.stats.durbin_watson(model.resid)\n",
    "        print(f\"\\n--- Diagnostic Check for '{feature_to_analyze}' ---\")\n",
    "        print(f\"Durbin-Watson Statistic: {durbin_watson_stat:.4f}\")\n",
    "        print(\"A value near 2.0 suggests no significant first-order autocorrelation.\")\n",
    "\n",
    "    if show_plot:\n",
    "        # --- Step 6: Visualize the Results ---\n",
    "        plot_df = df_monthly.copy()\n",
    "        plot_df['pred_pre'] = model.predict(plot_df.assign(intervention=0, post_intervention_time=0))\n",
    "        plot_df['pred_post'] = model.predict(plot_df)\n",
    "        plot_df['pred_counterfactual'] = model.predict(plot_df.assign(intervention=0, post_intervention_time=0))\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.scatter(plot_df['snapshot_ts'], plot_df[feature_to_analyze], label='Observed Monthly Mean', color='gray', alpha=0.7)\n",
    "\n",
    "        pre_intervention_data = plot_df[plot_df['intervention'] == 0]\n",
    "        plt.plot(pre_intervention_data['snapshot_ts'], pre_intervention_data['pred_pre'], label='Pre-Intervention Trend', color='blue')\n",
    "\n",
    "        post_intervention_data = plot_df[plot_df['intervention'] == 1]\n",
    "        plt.plot(post_intervention_data['snapshot_ts'], post_intervention_data['pred_post'], label='Post-Intervention Trend', color='red')\n",
    "        plt.plot(post_intervention_data['snapshot_ts'], post_intervention_data['pred_counterfactual'], label='Counterfactual Trend', color='blue', linestyle='--')\n",
    "\n",
    "        plt.axvline(x=intervention_date, color='black', linestyle='--', label=f\"Intervention ({intervention_date.strftime('%b %Y')})\")\n",
    "        plt.title(f'Interrupted Time Series Analysis of {feature_to_analyze}', fontsize=16)\n",
    "        plt.xlabel('Date (Month)', fontsize=12)\n",
    "        plt.ylabel(f'Mean {feature_to_analyze}', fontsize=12)\n",
    "        plt.legend(loc='best')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "# --- Bulk Analysis Function for All Features ---\n",
    "\n",
    "def run_bulk_its_analysis(df_monthly, feature_columns, intervention_date):\n",
    "    \"\"\"\n",
    "    Runs ITS analysis for a list of features and returns a summary DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df_monthly (pd.DataFrame): The prepared monthly DataFrame.\n",
    "        feature_columns (list): A list of feature names to analyze.\n",
    "        intervention_date (pd.Timestamp): The date of the intervention.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame summarizing the ITS results for each feature.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    print(\"\\n--- Running ITS for all features ---\")\n",
    "    for feature in feature_columns:\n",
    "        try:\n",
    "            # Run analysis without plotting or printing for each loop\n",
    "            model = run_its_analysis(df_monthly, feature, intervention_date, show_plot=False, print_summary=False)\n",
    "\n",
    "            if model is None:\n",
    "                continue\n",
    "\n",
    "            # Extract the coefficients and p-values of interest\n",
    "            results.append({\n",
    "                'feature': feature,\n",
    "                'beta1_pre_trend': model.params.get('time', np.nan),\n",
    "                'beta2_level_change': model.params.get('intervention', np.nan),\n",
    "                'beta3_trend_change': model.params.get('post_intervention_time', np.nan),\n",
    "                'p_value_level_change': model.pvalues.get('intervention', np.nan),\n",
    "                'p_value_trend_change': model.pvalues.get('post_intervention_time', np.nan),\n",
    "                'durbin_watson': sm.stats.durbin_watson(model.resid)\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Could not run analysis for '{feature}': {e}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T20:46:26.562168Z",
     "start_time": "2026-02-01T20:46:20.573505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Set a professional style for plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# --- Step 1: Load and Preprocess Your Data ---\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(input_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{input_file}' was not found.\")\n",
    "\n",
    "# --- Data Cleaning and Type Conversion ---\n",
    "df['snapshot_ts'] = pd.to_datetime(df['snapshot_ts'], utc=True)\n",
    "df.set_index('snapshot_ts', inplace=True)\n",
    "\n",
    "# --- Step 2: Aggregate Data to a Monthly Time Series ---\n",
    "feature_columns = [\n",
    "    'p_t', 'lexical_spike_delta', 'perplexity', 'burstiness', 'mean_dep_depth',\n",
    "    'clause_ratio', 'voice_ratio', 'fre', 'fog', 'chars_per_sent',\n",
    "    'sents_per_para', 'nTTR', 'word_density', 'avg_line_len', 'citation_delta', 'ai_flag'\n",
    "]\n",
    "\n",
    "# Ensure only existing columns are used\n",
    "existing_features = [col for col in feature_columns if col in df.columns]\n",
    "\n",
    "df_monthly = df[existing_features].resample('MS').mean()\n",
    "df_monthly.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# --- Step 3: Prepare the Aggregated Data for ITS ---\n",
    "intervention_date = pd.to_datetime('2022-11-01', utc=True)\n",
    "n_time_points = len(df_monthly)\n",
    "\n",
    "df_monthly['time'] = np.arange(1, n_time_points + 1)\n",
    "df_monthly['intervention'] = (df_monthly['snapshot_ts'] >= intervention_date).astype(int)\n",
    "\n",
    "# Find the index corresponding to the intervention start\n",
    "intervention_indices = df_monthly.index[df_monthly['snapshot_ts'] >= intervention_date]\n",
    "if not intervention_indices.empty:\n",
    "    intervention_index = intervention_indices[0]\n",
    "    df_monthly['post_intervention_time'] = np.maximum(0, df_monthly.index - intervention_index + 1) * df_monthly['intervention']\n",
    "else:\n",
    "    print(f\"Warning: The intervention date {intervention_date} was not found in the monthly data.\")\n",
    "    df_monthly['post_intervention_time'] = 0\n",
    "\n",
    "print(\"--- Data prepared and ready for analysis ---\")\n",
    "\n",
    "\n"
   ],
   "id": "245929c27c8484e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data prepared and ready for analysis ---\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T20:46:26.635140Z",
     "start_time": "2026-02-01T20:46:26.575698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- USAGE EXAMPLE 2: Run bulk analysis and get a summary table ---\n",
    "print(\"\\n\\n*** Running analysis for all features ***\")\n",
    "results_df = run_bulk_its_analysis(df_monthly, existing_features, intervention_date)\n",
    "print(\"\\n--- Summary of ITS Results for All Features ---\")\n",
    "print(results_df.to_string())"
   ],
   "id": "30aabe1224646c09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Running analysis for all features ***\n",
      "\n",
      "--- Running ITS for all features ---\n",
      "\n",
      "--- Summary of ITS Results for All Features ---\n",
      "                feature  beta1_pre_trend  beta2_level_change  beta3_trend_change  p_value_level_change  p_value_trend_change  durbin_watson\n",
      "0                   p_t         0.000087           -0.000039           -0.000067              0.938151              0.406157       1.680688\n",
      "1   lexical_spike_delta         0.000087           -0.000039           -0.000067              0.938151              0.406157       1.680688\n",
      "2            perplexity        -1.415893           -6.723842            2.091162              0.456208              0.146306       1.938288\n",
      "3            burstiness        -0.000377            0.017541            0.000452              0.055382              0.741752       2.555286\n",
      "4        mean_dep_depth         0.000138            0.004770            0.000469              0.803930              0.875893       1.289221\n",
      "5          clause_ratio         0.001052           -0.003769           -0.000055              0.807836              0.981831       2.670101\n",
      "6           voice_ratio         0.000013           -0.001311            0.000079              0.015703              0.320595       2.488703\n",
      "7                   fre         0.131026           -0.756990           -0.153747              0.277570              0.162765       1.485961\n",
      "8                   fog        -0.035833            0.142567            0.044371              0.351683              0.072057       1.466724\n",
      "9        chars_per_sent        -0.253048            0.822556            0.554161              0.728892              0.145415       1.204665\n",
      "10       sents_per_para         1.599544           -7.050634           -1.917589              0.129658              0.012237       2.248072\n",
      "11                 nTTR         0.010750           -0.081288           -0.008119              0.008952              0.080188       2.349648\n",
      "12         word_density        -0.030170            0.119630            0.039124              0.181429              0.008793       1.921026\n",
      "13         avg_line_len       288.216914         -792.028695         -338.533947              0.243091              0.003570       2.220751\n",
      "14       citation_delta         0.000075           -0.000369           -0.000051              0.185763              0.237663       2.084849\n",
      "15              ai_flag         0.000213            0.012451           -0.000137              0.088669              0.901569       1.553720\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T20:46:41.769151Z",
     "start_time": "2026-02-01T20:46:41.759277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "one_feature = 'lexical_spike_delta'\n",
    "# run_its_analysis(df_monthly, one_feature, intervention_date)"
   ],
   "id": "973a3ca401090f65",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e985822ec9dc589b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
